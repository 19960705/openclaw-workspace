
# 🎬 AI Master 可控视频制作工作流学习笔记
**来源**：微博 @AI Master | **日期**：2026-02-22

---

## 📌 核心观点

**业余 vs 专业**
- ❌ 业余：反复生成片段碰运气，追求「出图质量」
- ✅ 专业：先设计镜头结构，再让模型执行，追求「镜头控制」

**关键转变**
- 从「抽卡碰运气」→「可控流程」
- 从「学提示词」→「学导演」
- AI 不再是随机生成工具，而是可调度的摄影系统

---

## 🎯 三步工作流

### 第一步：制作「主镜头」图像
- **工具**：任何图像生成模型（Midjourney、DALL-E、Stable Diffusion 等）
- **目的**：锁定角色、服装、场景、光线、风格
- **关键点**：
  - 不是随便一张图，是整个项目的基础
  - 提示词不在复杂，而在想清楚自己要什么
  - 这张图不满意，后面只会不断返工
- **必须确定**：
  - ✅ 角色长什么样
  - ✅ 穿什么
  - ✅ 场景在哪
  - ✅ 光线是冷是暖
  - ✅ 整体是写实还是风格化

---

### 第二步：用参考图生成「无限角度」
- **工具**：Nano Banana Pro、Qwen Image Edit 这类图像编辑模型
- **方法**：
  1. 上传第一步的主图作为参考图
  2. AI 自动读取角色、风格、光线信息
  3. 只需要告诉它：「我要什么角度」
- **不需要**：重新写 4K、电影感、真实光影……这些描述
- **价值**：把「风格控制权」交给图像本身，而不是每次重新用文字描述
- **效果**：只改变摄像机角度，其他元素基本保持一致
  - ✅ 角色没变
  - ✅ 衣服没变
  - ✅ 环境没变
  - ✅ 光线没漂移

**可用角度列表**
| 角度 | 叙事功能 |
|------|----------|
| 特写 | 让观众贴近情绪 |
| 大特写 | 放大冲突 |
| 低角度 | 强化力量感 |
| 高角度 | 让人物显得孤立 |
| 鸟瞰 | 建立空间关系 |
| 广角 | 交代环境 |
| 荷兰角 | 制造不稳定 |
| 手持 | 增加临场感 |
| 微距 | 展现细节 |
| 过肩 | 建立对话感 |

**思维转变**
- ❶ 旧思维：「生成一张好看的图」
- ❷ 新思维：「用镜头语言讲故事」

---

### 第三步：把图像变成真正的镜头
- **工具**：带首帧、尾帧控制的视频模型（如可灵 3.0）

**三个层级**

#### 层级 1：单镜头运动
- 上传一张图
- 让它做缓慢推进或轻微运动
- 画面会动起来，但结构还是单镜头

#### 层级 2：首帧 + 尾帧控制
- 上传两个不同角度的图
- 模型自动生成从 A 到 B 的转场
- 例子：
  - 从虚焦到清晰
  - 从广角推到特写
- 优势：不用手动剪辑，它会补齐中间的运动过程

#### 层级 3：多镜头模式
- 每个镜头 3-5 秒
- 分别设置起始帧和动作描述
- 最后生成一段完整序列
- 例子：广角开场 → 切特写 → 拉到鸟瞰
- 核心：你不是在拼素材，而是在安排镜头顺序

---

## 🎬 完整流程示例

```
主镜头图像
    ↓
10个不同角度（特写、广角、鸟瞰、低角度...）
    ↓
3-5个镜头组合（每个3-5秒）
    ↓
30秒短片
    ↓
✅ 角色一致
✅ 风格一致
✅ 光影稳定
✅ 只有角度和运动在变
```

---

## 💡 关键洞察

1. **先锁死，再衍生**
   - 主镜头是基础，锁死角色和风格
   - 后面所有角度、视频都从这张图衍生

2. **参考图 &gt; 文字描述**
   - 把「风格控制权」交给图像本身
   - 不要每次重新用文字描述

3. **角度自带叙事功能**
   - 不同角度不只是视觉变化
   - 从「镜头语言」角度思考，创作方式就变了

4. **设计镜头结构，而不是生成片段**
   - 先设计，再执行
   - 业余追求出图质量，专业追求镜头控制

---

## 🔗 与 Seedance 2.0 的结合

这个工作流可以完美补充我们之前的分镜脚本：

1. **Seedance 2.0**：提供分镜结构和镜头语言指导
2. **AI Master 方法**：提供 AI 实现的可控工作流

**结合使用**
- 用 Seedance 2.0 设计分镜脚本
- 用 AI Master 三步法实现每个镜头
- 最后用多镜头模式拼接成完整视频

